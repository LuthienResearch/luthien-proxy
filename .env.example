# Luthien Control Environment Configuration
# Copy this file to .env and fill in your actual values

# LLM Provider API Keys (used by the proxy to authenticate to upstream providers)
# These are the REAL API keys that the proxy uses to call OpenAI/Anthropic
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# V2 Gateway Configuration
# PROXY_API_KEY: The API key that clients use to authenticate to the Luthien proxy
# Claude Code and other clients will use this key to authenticate to the proxy
PROXY_API_KEY=sk-luthien-dev-key
V2_GATEWAY_HOST=localhost
V2_GATEWAY_PORT=8000
V2_POLICY_CONFIG=/app/config/v2_config.yaml

# Security Configuration
# MAX_REQUEST_SIZE: Maximum allowed request body size in bytes (default: 10485760 = 10MB)
# Prevents DoS attacks via oversized payloads
MAX_REQUEST_SIZE=10485760

# PostgreSQL Configuration
POSTGRES_USER=luthien
POSTGRES_PASSWORD=luthien_dev_password
POSTGRES_DB=luthien_control
POSTGRES_PORT=5432
DATABASE_URL=postgresql://luthien:luthien_dev_password@db:5432/luthien_control

# Redis Configuration
REDIS_URL=redis://redis:6379
REDIS_PORT=6379


# Local LLM Gateway (OpenAI-compatible) for policy scoring
LOCAL_LLM_PORT=4010

# Ollama (local model host) port
OLLAMA_PORT=11434


# Test model used by local scripts (trace/sanity/tests)
# Set this to a model that exists for your API keys when calling through the proxy
# e.g., gpt-4o, gpt-4o-mini, or a local model via the local LLM gateway
TEST_MODEL=gpt-5
