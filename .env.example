# Luthien Control Environment Configuration
# Copy this file to .env and fill in your actual values

# PostgreSQL Configuration
POSTGRES_USER=luthien
POSTGRES_PASSWORD=luthien_dev_password
POSTGRES_DB=luthien_control
POSTGRES_PORT=5432
DATABASE_URL=postgresql://luthien:luthien_dev_password@localhost:5432/luthien_control

# LiteLLM Database (separate database for LiteLLM)
LITELLM_DATABASE_URL=postgresql://litellm:litellm_dev_password@db:5432/litellm_db

# Redis Configuration
REDIS_URL=redis://redis:6379
REDIS_PORT=6379

# LiteLLM Proxy Configuration
LITELLM_MASTER_KEY=sk-luthien-dev-key
LITELLM_PORT=4000
LITELLM_LOG=INFO

# Local LLM Gateway (OpenAI-compatible) for policy scoring
LOCAL_LLM_PORT=4010

# Ollama (local model host) port
OLLAMA_PORT=11434

# Control Plane Configuration
CONTROL_PLANE_URL=http://control-plane:8081
CONTROL_PLANE_PORT=8081
LOG_LEVEL=INFO

# Control Plane Config (consolidated)
# Path inside the container to the consolidated config that selects the active
# policy and inlines its options. Defaults to /app/config/luthien_config.yaml if not set.
LUTHIEN_POLICY_CONFIG=/app/config/luthien_config.yaml

# LLM Provider API Keys (required)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Test model used by local scripts (trace/sanity/tests)
# Set this to a model that exists for your API keys when calling through the proxy
# e.g., gpt-4o, gpt-4o-mini, or a local model via the local LLM gateway
TEST_MODEL=gpt-5

CONTROL_PLANE_STREAM_TIMEOUT=300 # Timeout for streaming responses from control plane to litellm (in seconds)
# if the control plane doesn't respond with a chunk or keepalive within this time, the stream will error out
