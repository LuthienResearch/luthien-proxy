# Default AI Control Policy Configuration
# This defines the behavior of the control system

version: "0.1.0"
name: "default"

# Trusted monitoring settings
trusted_monitor:
  # Threshold for deferring to trusted model (0.0 = never, 1.0 = always)
  defer_threshold: 0.7

  # Model configuration for trusted supervision
  model:
    name: "llama3-trusted"
    api_base: "http://ollama:11434"
    model_id: "llama3.1:8b"
    temperature: 0.1
    max_tokens: 1000

# Streaming response monitoring
streaming:
  # Check every N characters for suspiciousness
  max_chars_before_check: 400

  # Halt stream if suspiciousness exceeds this threshold
  halt_threshold: 0.9

  # Buffer size for chunk evaluation
  buffer_size: 1000

# Defer-to-resample protocol settings
resample:
  # Enable resampling protocol
  enabled: true

  # Number of alternative responses to generate
  k: 3

  # Score threshold to trigger resampling
  trigger_threshold: 0.6

  # If minimum score across samples exceeds this, trigger audit
  audit_if_min_score_gt: 0.85

  # Temperature variation for alternatives
  temperature_range: [0.5, 1.0]

# Untrusted monitoring settings (disabled by default)
untrusted_monitor:
  # Enable untrusted self-monitoring
  enabled: false

  # Honeypot configuration
  honeypots:
    # Fraction of upfront evaluation that should be honeypots
    upfront_fraction: 0.15

    # Ongoing honeypot injection rate (per 100 requests)
    ongoing_rate: 0.05

    # Shutdown untrusted monitor if false negative rate exceeds this
    shutdown_threshold_fnr: 0.2

    # Re-enable after this many successful validations
    recovery_threshold: 10

  # Use trusted model for paraphrasing to reduce collusion
  paraphraser: "trusted"

  # Ensemble weights for trusted vs untrusted scores
  ensemble_weights:
    trusted: 0.7
    untrusted: 0.3

# Budget management
budgets:
  # Maximum human audits per episode
  max_audits_per_episode: 5

  # Maximum human audits per day (global)
  max_audits_per_day: 100

  # Audit allocation strategy: "exponential", "linear", "threshold"
  allocation_strategy: "exponential"

# Request modification settings
request_modifications:
  # Enable system prompt hardening
  system_prompt_hardening: true

  # Tool/function call gating
  tool_gating:
    enabled: true
    allowed_tools: ["web_search", "calculator", "file_read"]
    blocked_tools: ["code_execution", "shell_access"]

  # Content filtering
  content_filtering:
    enabled: true
    block_patterns: ["execute:", "eval(", "system("]

# Response modification settings
response_modifications:
  # Enable trusted editing of responses
  trusted_editing: true

  # Redact sensitive information
  redaction:
    enabled: true
    patterns: ["api_key", "password", "secret"]

# Alerting configuration
alerts:
  # Alert channels for different event types
  channels:
    high_risk: ["slack:#ai-incidents", "pagerduty:ai-ops"]
    monitor_shutdown: ["slack:#ai-incidents", "email:admin@company.com"]
    audit_triggered: ["slack:#ai-incidents"]
    budget_exhausted: ["email:admin@company.com"]

  # Alert thresholds
  thresholds:
    # Alert if episode has this many interventions
    interventions_per_episode: 10

    # Alert if global intervention rate exceeds this (per hour)
    intervention_rate: 50

    # Alert if audit queue length exceeds this
    audit_queue_length: 20

# Logging and observability
logging:
  # Log all decisions for audit
  log_all_decisions: true

  # Include request/response content in logs
  include_content: true

  # Log level: DEBUG, INFO, WARNING, ERROR
  level: "INFO"

  # Retention period for logs (days)
  retention_days: 90

# Development/testing settings
development:
  # Use mock models for testing
  use_mock_models: false

  # Bypass certain checks in dev mode
  bypass_honeypots: false

  # Enhanced logging in development
  verbose_logging: true
