# LiteLLM configuration for the local scoring model (OpenAI-compatible)

model_list:
  - model_name: gemma2:2b
    litellm_params:
      model: ollama/gemma2:2b
      api_base: http://127.0.0.1:11434
      temperature: 0.0
      max_tokens: 256
  - model_name: gemma-scorer
    litellm_params:
      model: ollama/gemma2:2b
      api_base: http://127.0.0.1:11434
      temperature: 0.0
      max_tokens: 256
  - model_name: openai/gemma-scorer
    litellm_params:
      model: ollama/gemma2:2b
      api_base: http://127.0.0.1:11434
      temperature: 0.0
      max_tokens: 256

litellm_settings:
  callbacks: []
  json_logs: false
  log_raw_request_response: false
  master_key: ${LITELLM_MASTER_KEY}
  disable_spend_logs: true
  disable_master_key_return: true
  disable_key_name: true

general_settings:
  health_check: true
  request_timeout: 120

environment: production
