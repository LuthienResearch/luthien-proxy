# LiteLLM Configuration for Luthien Control
# Supports multiple LLM providers with AI control hooks

model_list:
  # OpenAI models (main untrusted models)
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 100000
      temperature: 0.7

  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 100000
      temperature: 0.7

  - model_name: gpt-5
    litellm_params:
      model: openai/gpt-5
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 128000

  - model_name: o3
    litellm_params:
      model: openai/o3
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 50000

  # Anthropic models
  - model_name: claude-3-5-sonnet
    litellm_params:
      model: anthropic/claude-3-5-sonnet-20241022
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 10000

  - model_name: claude-3-5-haiku
    litellm_params:
      model: anthropic/claude-3-5-haiku-20241022
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 100000

  - model_name: claude-sonnet-4
    litellm_params:
      model: anthropic/claude-sonnet-4-20250514
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 100000

  - model_name: claude-opus-4-1
    litellm_params:
      model: anthropic/claude-opus-4-1-20250805
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 100000

  - model_name: anthropic/claude-sonnet-4-5
    litellm_params:
      model: anthropic/claude-sonnet-4-5-20250929
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 200000

  # Demo dummy provider (for testing AI control with tool calls)
  - model_name: dummy-agent
    litellm_params:
      model: openai/dummy-model
      api_base: http://dummy-provider:8080/v1
      api_key: dummy-key

  - model_name: judge-scorer
    litellm_params:
      model: openai/judge-scorer
      api_base: http://dummy-provider:8080/v1
      api_key: dummy-key


# LiteLLM proxy settings
litellm_settings:
  # Enable sending all responses through the Luthien control plane
  callbacks: ["unified_callback.unified_callback"]
  # callbacks: ["replay_callback.replay_callback"]

  # Model parameter handling
  drop_params: true  # Drop unsupported params to improve compatibility with gpt-5/o3/Responses API

  # Database configuration for logging and state
  store_model_in_db: true
  store_prompts_in_spend_logs: true

  # Request/response logging
  json_logs: true
  log_raw_request_response: true

  # Security settings
  master_key: os.environ/LITELLM_MASTER_KEY
  ui_access_mode: "admin_only"

  # Performance settings
  redis_url: os.environ/REDIS_URL
  cache_responses: true
  cache_params:
    ttl: 300  # 5 minutes

  # Streaming settings
  stream_response: true

# General settings
general_settings:
  # Health check endpoint
  health_check: true

  # CORS settings for development
  cors_origins: ["http://localhost:3000", "http://localhost:8080"]

  # Request timeout
  request_timeout: 600  # 10 minutes for long requests

  # Rate limiting (if needed)
  max_requests_per_minute: 100

  # aggressive logging
  store_model_in_db: true
  store_prompts_in_spend_logs: true

# Environment-specific overrides
environment: development
